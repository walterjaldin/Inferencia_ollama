# ğŸ§  Inferencia Distribuida con Ollama

Este proyecto permite distribuir consultas a modelos LLM (como LLaMA 3) a travÃ©s de mÃºltiples nodos en una red local, usando el motor de inferencia **Ollama**.

---

## ğŸ“¦ Componentes

- **`setup_nodo.sh`**: Script para instalar y configurar automÃ¡ticamente un nodo con Ollama (soporta Debian y Arch).
- **`orquestador_ollama.py`**: Orquestador que escanea la red local, detecta los nodos activos y distribuye los prompts en modo round-robin.
- **`nodos/nodos.txt`**: Archivo que guarda los nodos detectados para uso persistente.

---

## âš™ï¸ Requisitos

- GNU/Linux (Debian, Ubuntu o Arch)
- Python 3.9 o superior
- Docker y acceso a `sudo`
- Acceso a una red local (LAN)

---

## ğŸš€ InstalaciÃ³n y Uso Paso a Paso

### ğŸ”¹ Paso 1: Configurar los Nodos

En cada mÃ¡quina que actuarÃ¡ como nodo de inferencia:

1. Clona el repositorio o copia el archivo `setup_nodo.sh`.
2. Da permisos de ejecuciÃ³n y ejecÃºtalo:

```bash
chmod +x setup_nodo.sh
./setup_nodo.sh
```

ğŸ”§ Esto harÃ¡:
- Detectar tu distribuciÃ³n (Debian o Arch)
- Instalar Docker y Ollama
- Instalar soporte para NVIDIA si se detecta GPU
- Dejar el nodo listo y escuchando en el puerto `11434`

---

### ğŸ”¹ Paso 2: Ejecutar el Orquestador (en el nodo principal)

1. AsegÃºrate de tener Python 3.9+ y `pip` instalado.
2. Instala las dependencias:

```bash
pip install -r requirements.txt
```

3. Ejecuta el orquestador:

```bash
python orquestador_ollama.py
```

ğŸ” El orquestador:
- Escanea la red `192.168.0.0/24`
- Detecta los nodos con Ollama activos
- Guarda sus IPs en `nodos/nodos.txt`
- Inicia una consola interactiva para enviar prompts

---

### ğŸ§  Uso del Orquestador

Una vez iniciado el script:

```text
ğŸ” Escaneando red local para encontrar nodos activos...
âœ… Nodos disponibles:
 - 192.168.0.5
 - 192.168.0.6

ğŸ§  Prompt > Â¿QuÃ© es la inteligencia artificial?
ğŸ“¡ Enviando a nodo 192.168.0.5...
ğŸ—¨ï¸  Respuesta: La inteligencia artificial es...
```

Puedes seguir enviando prompts uno tras otro. Para salir, simplemente escribe:

```text
ğŸ§  Prompt > salir
```

---

## ğŸ“ Estructura del Proyecto

```
â”œâ”€â”€ setup_nodo.sh            # Script de instalaciÃ³n del nodo
â”œâ”€â”€ orquestador_ollama.py    # Script principal de distribuciÃ³n
â”œâ”€â”€ requirements.txt         # Dependencias de Python
â”œâ”€â”€ LICENSE                  # Licencia MIT
â”œâ”€â”€ README.md                # Este archivo
â””â”€â”€ nodos/
    â””â”€â”€ nodos.txt            # Lista de nodos detectados
```

---

## ğŸ§ª Pruebas Realizadas

- InstalaciÃ³n automÃ¡tica en Arch y Debian
- EnvÃ­o de mÃºltiples prompts en modo round-robin
- Tolerancia a fallos (si un nodo se cae, rota al siguiente)
- Persistencia de nodos detectados entre ejecuciones

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.
